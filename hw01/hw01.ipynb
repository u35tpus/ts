{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "#pip3 install  scikit-plot\n",
    "import scikitplot as skplt\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read data frame and rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Wine.txt\", sep='\\t')\n",
    "features = ['alcohol', 'malic_acid', 'ash','ash_alcalinity','magnesium','phenols','flavanoids',\n",
    "              'nonflavanoid','proanthocyanins','color','hue','OD280_OD315 ','proline']\n",
    "\n",
    "df.columns = features + ['d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Look at first rows to check dataframe is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Check we have no NaN values in dataframe and check column types are not \"objects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Split into train set, validation set, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def split_train_test(data, test_ratio=0.2):\n",
    "    shuffled_indices = np.random.permutation(len(data)) \n",
    "    test_set_size = int(len(data) * test_ratio) \n",
    "    test_indices = shuffled_indices[:test_set_size] \n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "train_set, test_set = split_train_test(df, 0.2,)\n",
    "\n",
    "print(\"train set shape:{}\\n test set shape:{}\\n\".format(train_set.shape, test_set.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Copy train set to make sure we don't mutate it by chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines = train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Check correlations between features visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "corr = wines.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. We see that\n",
    "  a) i1 and i13 correlate with target\n",
    "  b) we see thatn i1 and i13 dont corellate with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines.hist(bins=50, figsize=(20,15)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Check visually whether correlated features really separate target well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"d\", y=\"alcohol\", data=wines)\n",
    "ax = sns.swarmplot(x=\"d\", y=\"alcohol\", data=wines, color=\".25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x=\"d\", y=\"proline\", data=wines)\n",
    "ax = sns.swarmplot(x=\"d\", y=\"proline\", data=wines, color=\".25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. We will need customer transformer for dropping non-relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Transformer that extracts columns passed as argument to its constructor \n",
    "class ColumnSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Construct pipeline using dropper and standard scaler transformers. \n",
    "We need scaling as many classifiers allow 0..1 scale only for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_model(tset, vset, depth, pipe,clf):\n",
    "    Xtest = tset[features]\n",
    "    Ytest = tset['d']\n",
    "    Xvalidation = vset[features]\n",
    "    Yvalidation = vset['d']\n",
    "    clf.fit(pipe.fit_transform(Xtest), Ytest)\n",
    "    return f1_score(Yvalidation,  clf.predict(pipe.fit_transform(Xvalidation)), average='macro')\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "depths=np.arange(1,10)\n",
    "\n",
    "scores = []\n",
    "for d in depths:\n",
    "    s = np.zeros(4)\n",
    "    idx=0\n",
    "    for train, test in kf.split(train_set):\n",
    "        s[idx] = try_model(train_set.iloc[train], train_set.iloc[test],d, Pipeline([('std_scaler', StandardScaler())]),\n",
    "                                        RandomForestClassifier(max_depth=d, random_state=0))\n",
    "        idx+=1\n",
    "    scores.append(s.mean())    \n",
    "\n",
    "    \n",
    "plt.scatter(x=depths, y = scores)\n",
    "plt.xticks(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=np.arange(1,20)\n",
    "\n",
    "scores = []\n",
    "for d in depths:\n",
    "    s = np.zeros(4)\n",
    "    idx=0\n",
    "    for train, test in kf.split(train_set):\n",
    "        s[idx] = try_model(train_set.iloc[train], train_set.iloc[test],d, Pipeline([('std_scaler', StandardScaler())]), \n",
    "                           DecisionTreeClassifier(random_state=0, max_depth=d))\n",
    "        idx+=1\n",
    "    scores.append(s.mean())    \n",
    "\n",
    "plt.scatter(x=depths, y = scores)\n",
    "plt.xticks(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So best params  for random forest:\n",
    "depth = 4\n",
    "\n",
    "X = train_set[features]\n",
    "y = train_set['d']\n",
    "    \n",
    "\n",
    "rf = RandomForestClassifier(max_depth=depth, random_state=0).fit(Pipeline([('std_scaler', StandardScaler())]).fit_transform(X),y)\n",
    "\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "ax = feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So best params  for random forest:\n",
    "depth = 3\n",
    "\n",
    "X = train_set[features]\n",
    "y = train_set['d']\n",
    "    \n",
    "\n",
    "     \n",
    "    \n",
    "dt = DecisionTreeClassifier(random_state=0, max_depth=d).fit(Pipeline([('std_scaler', StandardScaler())]).fit_transform(X),y)\n",
    "\n",
    "\n",
    "tree.plot_tree(dt.fit(X, y), feature_names=features) \n",
    "\n",
    "feature_importances = pd.DataFrame(dt.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "ax = feature_importances.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "            ('dropper', ColumnSelector(['alcohol','proline'])),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "y = train_set['d']\n",
    "clf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0).fit(pipeline.fit_transform(train_set), y)\n",
    "y_score = clf.decision_function(pipeline.fit_transform(test_set))\n",
    "\n",
    "skplt.metrics.plot_roc_curve(test_set['d'], y_score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So best params  for random forest:\n",
    "depth = 4\n",
    "\n",
    "X = train_set[features]\n",
    "y = train_set['d']\n",
    "    \n",
    "\n",
    "rf = RandomForestClassifier(warm_start=True, oob_score=True, \n",
    "                            max_depth=depth, random_state=0).fit(Pipeline([('std_scaler', StandardScaler())]).fit_transform(X),y)\n",
    "\n",
    "feature_importances = pd.DataFrame(rf.feature_importances_,\n",
    "                                   index = X.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "rf_test_probas=rf.predict_proba(Pipeline([('std_scaler', StandardScaler())]).fit_transform(test_set[features]))\n",
    "\n",
    "print('Out of Bag Score:{}'.format(rf.oob_score_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def precision(mtrx):\n",
    "    true_positives, true_negatives, false_negatives, false_positives = mtrx\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "\n",
    "def falsepositiverate(mtrx):\n",
    "    true_positives, true_negatives, false_negatives, false_positives = mtrx\n",
    "    return false_positives / (false_positives + true_negatives)\n",
    "\n",
    "\n",
    "def recall(mtrx):\n",
    "    true_positives, true_negatives, false_negatives, false_positives = mtrx\n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "\n",
    "def f1_score(mtrx):\n",
    "    return 2 / (precision(mtrx) + recall(mtrx))\n",
    "\n",
    "\n",
    "def get_confusion_matrix(labels, probas, target, thre):\n",
    "    true_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    for i in range(0, len(labels)):\n",
    "        if labels[i] == target:\n",
    "            positive = True\n",
    "        else:\n",
    "            positive = False\n",
    "\n",
    "        proba = probas[i][target]\n",
    "\n",
    "        if proba > thre and positive:\n",
    "            true_positives += 1\n",
    "        if proba > thre and not positive:\n",
    "            false_positives += 1\n",
    "        if proba <= thre and positive:\n",
    "            false_negatives += 1\n",
    "        if proba <= thre and not positive:\n",
    "            true_negatives += 1\n",
    "    return (true_positives, true_negatives, false_negatives, false_positives)\n",
    "\n",
    "def roc(lbls, probas, tgt):\n",
    "    thresholds = np.linspace(0, 1, 20)\n",
    "\n",
    "    x = np.zeros(len(thresholds))\n",
    "    y = np.zeros(len(thresholds))\n",
    "\n",
    "    idx = 0\n",
    "    for t in thresholds:\n",
    "        mtrx = get_confusion_matrix(labels=lbls, probas=probas, target=tgt, thre=t)\n",
    "\n",
    "        tpr = recall(mtrx)\n",
    "        fpr = falsepositiverate(mtrx)\n",
    "        x[idx] = fpr\n",
    "        y[idx] = tpr\n",
    "\n",
    "        idx+=1\n",
    "\n",
    "    return (x,y)\n",
    "\n",
    "\n",
    "tuples = []\n",
    "for i in np.arange(0, 3):    \n",
    "    rf_x, y =  roc(test_set['d'].values, rf_test_probas, i)\n",
    "    tuples.append((rf_x,y))\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "\n",
    "plots = []\n",
    "plots.append(ax1)\n",
    "plots.append(ax2)\n",
    "plots.append(ax3)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for p in plots:\n",
    "    x,y = tuples[i]\n",
    "    p.plot(x, y)\n",
    "    p.set_title('Class %d'%idx)\n",
    "    idx+=1\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
